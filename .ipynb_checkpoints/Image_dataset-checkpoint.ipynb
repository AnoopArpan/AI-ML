{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f6f7538-87f0-4840-a616-935c2d98c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e498f9-ca3b-489e-b3d7-f2fa67d68155",
   "metadata": {},
   "source": [
    "### Detect face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "476df18c-7809-49f0-b1c9-cbc6ed03d2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(frame):\n",
    "    detector=cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")\n",
    "    face=detector.detectMultiScale(frame,1.2)\n",
    "    return face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef0765-80a2-426f-b132-0b13592ad79b",
   "metadata": {},
   "source": [
    "### Gray scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f52bb71-ce00-478a-ad09-101f50d6ac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_scale(image):\n",
    "    img=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bd4b32-8f10-46f2-84e1-24c3a16dd4e3",
   "metadata": {},
   "source": [
    "### Cut face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1381deb3-0548-4032-9ffa-918ac4fafe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_face(image,face_coords):\n",
    "    faces=[]\n",
    "    for (x,y,w,h) in face_coords:\n",
    "        img=image[y:y+h,x:x+w]\n",
    "        faces.append(img)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f893f1c7-5ce2-4c36-b870-afa638afedaa",
   "metadata": {},
   "source": [
    "### Normalize intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af3a5054-48a8-476a-b83a-cb3ef4684715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_intensity(images):\n",
    "    normalize_image=[]\n",
    "    for image in images:\n",
    "        img=cv2.equalizeHist(image)\n",
    "        normalize_image.append(img)\n",
    "    return normalize_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24811434-e6fc-49cf-9d38-074487e6d268",
   "metadata": {},
   "source": [
    "### Resize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "202a2998-e2f2-444f-9dc0-aed1fcf1f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(images,size=(80,100)):\n",
    "    resized_images=[]\n",
    "    for img in images:\n",
    "        image=cv2.resize(img,size)\n",
    "        resized_images.append(image)\n",
    "    return resize_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e0322b-9d24-420a-9122-f04b1ae33f45",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96cf1666-0167-4952-ac9b-0c1186460563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(image,face_coords):\n",
    "    faces=cut_face(image,face_coords)\n",
    "    faces=normalize_intensity(faces)\n",
    "    faces=resize(faces)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b854f846-3dbe-481e-a879-24be3ceadee2",
   "metadata": {},
   "source": [
    "### Plot fxn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4508bde5-1338-4f45-bbc8-9e75762d8e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fxn(image,title=\"\"):\n",
    "    if image.shape==3:\n",
    "        cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.imshow(image,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c2e1c7-271c-4c93-9048-1e72a1807c53",
   "metadata": {},
   "source": [
    "### Draw rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c72f8d3-d646-44c3-8833-2aba1af6e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(image,coords):\n",
    "    for (x,y,w,h) in coords:\n",
    "        cv2.rectangle(image,(x,y),(x+w,y+h),(0,0,225),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807f07d6-c7b5-4963-9f4c-32f8bf653f1c",
   "metadata": {},
   "source": [
    "### Lets create a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a749dd56-3451-46d6-99dd-be4d7b054458",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam=cv2.VideoCapture(1)\n",
    "name=input(\"Enter folder name :\")\n",
    "no_sample=int(input(\"Enter sample numbers :\"))\n",
    "folder=\"user_data1/\"+name.lower()\n",
    "if os.path.exists(folder):\n",
    "    print(\"Folder with this name is already existed\")\n",
    "else:\n",
    "    os.mkdir(folder)\n",
    "    start_cap=False\n",
    "    sample=1\n",
    "    cv2.namedWindow(name,cv2.WINDOW_NORMAL)\n",
    "    while True:\n",
    "        rect,frame=cam.read()\n",
    "        gray=gray_scale(frame)\n",
    "        face_coord=detect_face(gray)\n",
    "        if len(face_coord)>0:\n",
    "            pass ###call pipeline face=pipline\n",
    "            ### img_name=str(sample)+\".jpg\"\n",
    "        else:\n",
    "            print(\"NO FACE FOUND!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00b930f-5536-47d5-8b13-af9b2e04590b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
